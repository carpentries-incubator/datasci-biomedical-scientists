---
title: "Data analysis and results"
teaching: 0
exercises: 0
questions:
- "Key question (FIXME)"
objectives:
- "First learning objective. (FIXME)"
keypoints:
- "First key point. Brief Answer to questions. (FIXME)"
---

## Data exploration and insights

Data wrangling involves cleaning data so it can be easily read and analysed by machines. It can also involve integration, extraction, removing missing points, and anything that makes data useable and functional. Regardless of the methods, the code involved with data cleaning steps should be carefully documented so that the steps involved can be repeated from raw data to cleaned data. 

When working with data sets, `ggplot` (in R) or `matplotlib`/`seaborn` (in Python) libraries provide attractive figures that can be produced very quickly. Visualising data should not not wait for the point of publication, and can be used to explore data from the start, and also illustrate methodology. This is particularly valuable in Jupyter Notebooks. Code to produce figures should be literate, functional, reuseable in the same way as data cleaning and analysis code. That way future visualisations can be easily updated or reused. 


- Data Visualisation as a tool
  - Reference: https://helenajambor.wordpress.com/2022/01/04/science-visualization-trends-of-2021/

## Statistical analysis

(Need to discuss this further, what is patronising?)

- Choices for statistical analysis

## Communicating Results

- What elements are involved

## Producing figures

- Best practices
- Versions
- Publication with persistent identifier

## Conclusion
- What gaps have we filled in this section
- Project management overview 

## Resources for taking this to next level

- ​​https://the-turing-way.netlify.app/collaboration/new-community.html 

{% include links.md %}

